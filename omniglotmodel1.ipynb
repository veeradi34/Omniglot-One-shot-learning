{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1f-d_WHnPJG7FPFOJ9v_HkgS0Om1xGun-","authorship_tag":"ABX9TyNgWuMgoWYz7bEbbmbKvRnb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from glob import glob\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","\n"],"metadata":{"id":"oJafFZZiCR36","executionInfo":{"status":"ok","timestamp":1740588095157,"user_tz":-330,"elapsed":6,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZhrnIbbGTqp","executionInfo":{"status":"ok","timestamp":1740588096419,"user_tz":-330,"elapsed":12,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}},"outputId":"abeb5c13-4fad-45c7-a3b1-367fff5939e7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["class OmniglotDataset(Dataset):\n","    def __init__(self, data_paths, targets):\n","        self.data = data_paths\n","        self.targets = targets\n","\n","    def __getitem__(self, index):\n","        img_path = self.data[index]\n","        target = self.targets[index]\n","\n","        # Loading image\n","        img = Image.open(img_path).convert(\"L\")  # Converting to grayscale\n","        img = np.array(img, dtype=np.float32) / 255.0  # Normalizing\n","        img = torch.tensor(img).unsqueeze(0).float()\n","        return img, target\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","# 2. Function to load and split the dataset\n","def prepare_omniglot_dataset(root_dir, test_size=0.2):\n","    \"\"\"\n","    Load Omniglot dataset and split it into train and test sets\n","\n","    Args:\n","        root_dir: Path to the Omniglot dataset (should contain 'images_background' or similar)\n","        test_size: Proportion of data to use for test set\n","\n","    Returns:\n","        train_dataset, test_dataset\n","    \"\"\"\n","    print(f\"Loading Omniglot dataset from: {root_dir}\")\n","\n","    # Finding all image files and their paths\n","    all_images = []\n","\n","\n","    if os.path.exists(os.path.join(root_dir, 'images_background')):\n","\n","        background_images = glob(os.path.join(root_dir, 'images_background', '*', '*', '*.png'))\n","        all_images.extend(background_images)\n","\n","\n","        if os.path.exists(os.path.join(root_dir, 'images_evaluation')):\n","            evaluation_images = glob(os.path.join(root_dir, 'images_evaluation', '*', '*', '*.png'))\n","            all_images.extend(evaluation_images)\n","    else:\n","\n","        all_images = glob(os.path.join(root_dir, '*', '*', '*.png'))\n","\n","    if not all_images:\n","        raise ValueError(f\"No images found in {root_dir}. Please check the path.\")\n","\n","    print(f\"Found {len(all_images)} images total\")\n","\n","\n","    label_map = {}\n","    targets = []\n","\n","    for path in all_images:\n","        character_dir = os.path.dirname(path)\n","        if character_dir not in label_map:\n","            label_map[character_dir] = len(label_map)\n","        targets.append(label_map[character_dir])\n","\n","    # Split into train and test sets\n","    train_paths, test_paths, train_targets, test_targets = train_test_split(\n","        all_images, targets, test_size=test_size, stratify=targets, random_state=42\n","    )\n","\n","    print(f\"Split dataset into {len(train_paths)} training images and {len(test_paths)} test images\")\n","    print(f\"Number of unique classes: {len(label_map)}\")\n","\n","    # Create datasets\n","    train_dataset = OmniglotDataset(train_paths, train_targets)\n","    test_dataset = OmniglotDataset(test_paths, test_targets)\n","\n","    return train_dataset, test_dataset\n"],"metadata":{"id":"m3DZ20XnIIAu","executionInfo":{"status":"ok","timestamp":1740588097553,"user_tz":-330,"elapsed":39,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class SiameseOmniglotDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","        self.labels_to_indices = self._group_by_label()  # Group indices by label\n","\n","    def _group_by_label(self):\n","        \"\"\" Groups dataset indices by their labels. \"\"\"\n","        labels_to_indices = {}\n","        for i in range(len(self.dataset)):\n","            _, label = self.dataset[i]\n","            if label not in labels_to_indices:\n","                labels_to_indices[label] = []\n","            labels_to_indices[label].append(i)\n","        return labels_to_indices\n","\n","    def __getitem__(self, index):\n","        \"\"\" Returns a pair of images (same or different class) and a label. \"\"\"\n","        img1, label1 = self.dataset[index]\n","\n","        if random.random() < 0.5:\n","\n","            img2 = self.dataset[random.choice(self.labels_to_indices[label1])][0]\n","            label = 1\n","        else:\n","\n","            label2 = random.choice(list(self.labels_to_indices.keys()))\n","            while label2 == label1:\n","                label2 = random.choice(list(self.labels_to_indices.keys()))\n","            img2 = self.dataset[random.choice(self.labels_to_indices[label2])][0]\n","            label = 0\n","\n","        return img1, img2, torch.tensor(label, dtype=torch.float32)\n","\n","    def __len__(self):\n","        return len(self.dataset)\n"],"metadata":{"id":"9JlAqOEdINmb","executionInfo":{"status":"ok","timestamp":1740588098491,"user_tz":-330,"elapsed":32,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class SiameseNetwork(nn.Module):\n","    def __init__(self):\n","        super(SiameseNetwork, self).__init__()\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((6, 6))\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(256 * 6 * 6, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 128)\n","        )\n","\n","    def forward_once(self, x):\n","        x = self.cnn(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","    def forward(self, x1, x2):\n","        out1 = self.forward_once(x1)\n","        out2 = self.forward_once(x2)\n","        return out1, out2\n"],"metadata":{"id":"MOKkKCmQIR0d","executionInfo":{"status":"ok","timestamp":1740588099032,"user_tz":-330,"elapsed":24,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class ContrastiveLoss(nn.Module):\n","    def __init__(self, margin=2.0):\n","        super(ContrastiveLoss, self).__init__()\n","        self.margin = margin\n","\n","    def forward(self, out1, out2, label):\n","        distance = F.pairwise_distance(out1, out2, keepdim=True)\n","        loss = (1 - label) * distance.pow(2) + label * F.relu(self.margin - distance).pow(2)\n","        return loss.mean()\n","\n"],"metadata":{"id":"q_WdBfE-IWVO","executionInfo":{"status":"ok","timestamp":1740588099806,"user_tz":-330,"elapsed":16,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, criterion, optimizer, epochs=5):\n","    model.train()\n","    for epoch in range(epochs):\n","        epoch_loss = 0\n","        for batch_idx, (img1, img2, labels) in enumerate(train_loader):\n","            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","            out1, out2 = model(img1, img2)\n","            loss = criterion(out1, out2, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            epoch_loss += loss.item()\n","\n","\n","            if batch_idx % 50 == 0:\n","                print(f\"Epoch {epoch+1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | Loss: {loss.item():.4f}\")\n","\n","        print(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {epoch_loss/len(train_loader):.4f}\")\n","\n","\n","def evaluate(model, test_loader, criterion):\n","    model.eval()\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for img1, img2, labels in test_loader:\n","            img1, img2, labels = img1.to(device), img2.to(device), labels.to(device)\n","\n","\n","            out1, out2 = model(img1, img2)\n","\n","\n","            distance = F.pairwise_distance(out1, out2)\n","\n","\n","            loss = criterion(out1, out2, labels)\n","            total_loss += loss.item()\n","\n","\n","            predictions = (distance < 1.0).float()\n","\n","            correct += (predictions == labels).sum().item()\n","            total += labels.size(0)\n","\n","    accuracy = correct / total\n","    avg_loss = total_loss / len(test_loader)\n","    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%\")\n","    return accuracy"],"metadata":{"id":"fagzroKsIZuA","executionInfo":{"status":"ok","timestamp":1740588100514,"user_tz":-330,"elapsed":15,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def run_siamese_network(dataset_path, batch_size=32, epochs=10, test_size=0.2):\n","    \"\"\"\n","    Main function to prepare dataset, train and evaluate the Siamese Network\n","\n","    Args:\n","        dataset_path: Path to Omniglot dataset\n","        batch_size: Batch size for training\n","        epochs: Number of training epochs\n","        test_size: Proportion of data to use for testing\n","    \"\"\"\n","    # Preparing datasets\n","    train_dataset, test_dataset = prepare_omniglot_dataset(dataset_path, test_size)\n","\n","    # Creating Siamese datasets\n","    train_siamese_dataset = SiameseOmniglotDataset(train_dataset)\n","    test_siamese_dataset = SiameseOmniglotDataset(test_dataset)\n","\n","    # Creating data loaders\n","    train_loader = DataLoader(train_siamese_dataset, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(test_siamese_dataset, batch_size=batch_size, shuffle=False)\n","\n","    print(f\"Prepared dataloaders with batch size {batch_size}\")\n","\n","    # Initializing model, loss and optimizer\n","    model = SiameseNetwork().to(device)\n","    criterion = ContrastiveLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Training the model\n","    print(\"Starting training...\")\n","    train(model, train_loader, criterion, optimizer, epochs=epochs)\n","\n","    # Evaluating the model\n","    print(\"Evaluating model...\")\n","    accuracy = evaluate(model, test_loader, criterion)\n","\n","    # Saving the model\n","    save_path = \"/content/siamese_omniglot_model.pth\"\n","    torch.save(model.state_dict(), save_path)\n","    print(f\"Model saved to {save_path}\")\n","\n","    return model, accuracy\n","\n","\n","dataset_path = \"/content/drive/MyDrive/Few-Shot Learning for Handwritten Character Recognition/images_background\"\n","\n","# Running the Siamese Network\n","model, accuracy = run_siamese_network(\n","    dataset_path=dataset_path,\n","    batch_size=32,\n","    epochs=15,\n","    test_size=0.2\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dDjChw8ZInr4","executionInfo":{"status":"ok","timestamp":1740588137185,"user_tz":-330,"elapsed":35812,"user":{"displayName":"Veeraditya Parakh","userId":"15482308393056900989"}},"outputId":"554533e9-9012-4eb1-975e-2e9a6c172e4d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Omniglot dataset from: /content/drive/MyDrive/Few-Shot Learning for Handwritten Character Recognition/images_background\n","Found 385 images total\n","Split dataset into 308 training images and 77 test images\n","Number of unique classes: 20\n","Prepared dataloaders with batch size 32\n","Starting training...\n","Epoch 1/15 | Batch 0/10 | Loss: 1.6157\n","Epoch [1/15], Average Loss: 1.4956\n","Epoch 2/15 | Batch 0/10 | Loss: 1.0204\n","Epoch [2/15], Average Loss: 1.3424\n","Epoch 3/15 | Batch 0/10 | Loss: 1.6032\n","Epoch [3/15], Average Loss: 1.2991\n","Epoch 4/15 | Batch 0/10 | Loss: 1.1731\n","Epoch [4/15], Average Loss: 1.2412\n","Epoch 5/15 | Batch 0/10 | Loss: 1.2108\n","Epoch [5/15], Average Loss: 1.1567\n","Epoch 6/15 | Batch 0/10 | Loss: 1.1235\n","Epoch [6/15], Average Loss: 1.2103\n","Epoch 7/15 | Batch 0/10 | Loss: 1.2656\n","Epoch [7/15], Average Loss: 1.1571\n","Epoch 8/15 | Batch 0/10 | Loss: 1.1310\n","Epoch [8/15], Average Loss: 1.1543\n","Epoch 9/15 | Batch 0/10 | Loss: 1.1458\n","Epoch [9/15], Average Loss: 1.1215\n","Epoch 10/15 | Batch 0/10 | Loss: 1.2428\n","Epoch [10/15], Average Loss: 1.1702\n","Epoch 11/15 | Batch 0/10 | Loss: 1.1593\n","Epoch [11/15], Average Loss: 1.1748\n","Epoch 12/15 | Batch 0/10 | Loss: 1.1693\n","Epoch [12/15], Average Loss: 1.1807\n","Epoch 13/15 | Batch 0/10 | Loss: 1.0776\n","Epoch [13/15], Average Loss: 1.1259\n","Epoch 14/15 | Batch 0/10 | Loss: 1.1576\n","Epoch [14/15], Average Loss: 1.1457\n","Epoch 15/15 | Batch 0/10 | Loss: 1.1298\n","Epoch [15/15], Average Loss: 1.1748\n","Evaluating model...\n","Test Loss: 1.3597, Test Accuracy: 74.03%\n","Model saved to /content/siamese_omniglot_model.pth\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7fA7_9a3Iq1v"},"execution_count":null,"outputs":[]}]}